{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "cat_dogs_classifier (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "looking-letter"
      },
      "source": [
        "#Importing libraries\n",
        "from __future__ import print_function, division\n",
        "import glob\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from skimage import io, transform\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "from torch.nn import Sequential\n",
        "from torch.nn import functional as F\n",
        "from torch import nn, optim\n",
        "from sklearn.utils import resample\n",
        "import cv2\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "looking-letter",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI8SnxAWC5jb"
      },
      "source": [
        "#1. Загрузка данных"
      ],
      "id": "FI8SnxAWC5jb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEJRfoGCA_8G",
        "outputId": "37d02d1d-d8d1-4a03-9a81-9afa88fc7e09"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "xEJRfoGCA_8G",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d56yhbhBVEz",
        "outputId": "e6ecaf84-8369-4901-b895-1f7476e46bd0"
      },
      "source": [
        "%cd '/content/drive/MyDrive/cats_dogs_dataset/'"
      ],
      "id": "3d56yhbhBVEz",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/cats_dogs_dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "environmental-marine"
      },
      "source": [
        "#Walk trough all files in the dataset folder and take their names\n",
        "txt_files = glob.glob('*.txt')\n",
        "#List for annotations\n",
        "annotations = []\n",
        "#For each image get its annotations (labels)\n",
        "for file in txt_files:\n",
        "    with open(file, 'rt') as fd:\n",
        "        first_line = fd.readline().split()\n",
        "    annotations.append([file[:-4]] + first_line)\n",
        "#Create a dataframe with image name and its labels   \n",
        "annotations = pd.DataFrame(annotations, columns = ['image_name', 'class', 'x_min', 'y_min', 'x_max', 'y_max'])\n",
        "#Change classes values to 0 (cat) and 1 (dog) for binary classification\n",
        "annotations['class'] = annotations['class'].astype(float) - 1\n",
        "#Save the dataframe to the dataset folder\n",
        "annotations.to_csv(r'/content/drive/MyDrive/cats_dogs_dataset/annotations.csv', index=False)"
      ],
      "id": "environmental-marine",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JeqUy9HFtpy"
      },
      "source": [
        "#2. Класс датасета"
      ],
      "id": "2JeqUy9HFtpy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "challenging-luther"
      },
      "source": [
        "#Define a custom dataset class\n",
        "\"\"\"   \n",
        "       Arguments: \n",
        "                    df: pd.DataFrame file with names of images and their labels\n",
        "                    root_dir: name of files directory\n",
        "                    transform: images transformes\n",
        "\"\"\"\n",
        "class CatDogDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df, root_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform  \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        #Get image\n",
        "        img_name = self.df.iloc[idx]['image_name'] + '.jpg'\n",
        "        image = io.imread(img_name).astype('double')\n",
        "        #For images not in RGB change to 3-channel format\n",
        "        if image.ndim == 2:\n",
        "            image = np.stack((image,)*3, axis=-1)\n",
        "        #Get class label\n",
        "        dog_score = np.array([self.df.iloc[idx, 1]]).astype('double')\n",
        "        #Get bounding box coordinates\n",
        "        coords = np.array([self.df.iloc[idx, 2:]]).astype('double')\n",
        "        #Return an image and its class label and bbox coordinates\n",
        "        sample = {'image': image, 'dog_score': dog_score, 'coords': coords}\n",
        "        #Transform image and bbox\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        return sample"
      ],
      "id": "challenging-luther",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09okMJNwFzti"
      },
      "source": [
        "#3. Аугментации\n",
        "В качестве аугментаций используются: \\\\\n",
        " 1. Поворот на рандомный угол.\n",
        " 2. Горизонтальное отражение (случайное).\n",
        " 3. Скейлинг (в данной реализации в формате 240х240).\n",
        " 4. Перевод данных в тензорное представление.\n",
        "\n",
        "Также пиксели картинки приведены к диапазону [0, 1], bbox'ы -- к относительному положению на картинке. Нормализация не использовалась."
      ],
      "id": "09okMJNwFzti"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAGwrchE0JvU"
      },
      "source": [
        "def rotate_im(image, angle):\n",
        "    (h, w) = image.shape[:2]\n",
        "    (cX, cY) = (w // 2, h // 2)\n",
        "    M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
        "    cos = np.abs(M[0, 0])\n",
        "    sin = np.abs(M[0, 1])\n",
        "    nW = int((h * sin) + (w * cos))\n",
        "    nH = int((h * cos) + (w * sin))\n",
        "    M[0, 2] += (nW / 2) - cX\n",
        "    M[1, 2] += (nH / 2) - cY\n",
        "    image = cv2.warpAffine(image, M, (nW, nH))\n",
        "    return image\n",
        "\n",
        "def get_corners(bboxes):\n",
        "\n",
        "    width = (bboxes[:,2] - bboxes[:,0]).reshape(-1,1)\n",
        "    height = (bboxes[:,3] - bboxes[:,1]).reshape(-1,1)\n",
        "        \n",
        "    x1 = bboxes[:,0].reshape(-1,1)\n",
        "    y1 = bboxes[:,1].reshape(-1,1)\n",
        "        \n",
        "    x2 = x1 + width\n",
        "    y2 = y1 \n",
        "        \n",
        "    x3 = x1\n",
        "    y3 = y1 + height\n",
        "        \n",
        "    x4 = bboxes[:,2].reshape(-1,1)\n",
        "    y4 = bboxes[:,3].reshape(-1,1)\n",
        "        \n",
        "    corners = np.hstack((x1,y1,x2,y2,x3,y3,x4,y4))\n",
        "        \n",
        "    return corners\n",
        "        \n",
        "def rotate_bbox(corners, angle, cx, cy, h, w):\n",
        "\n",
        "    corners = corners.reshape(-1,2)\n",
        "    corners = np.hstack((corners, np.ones((corners.shape[0],1), dtype = type(corners[0][0]))))\n",
        "        \n",
        "    M = cv2.getRotationMatrix2D((cx, cy), angle, 1.0)\n",
        "        \n",
        "    \n",
        "    cos = np.abs(M[0, 0])\n",
        "    sin = np.abs(M[0, 1])\n",
        "        \n",
        "    nW = int((h * sin) + (w * cos))\n",
        "    nH = int((h * cos) + (w * sin))\n",
        "    M[0, 2] += (nW / 2) - cx\n",
        "    M[1, 2] += (nH / 2) - cy\n",
        "    calculated = np.dot(M,corners.T).T\n",
        "        \n",
        "    calculated = calculated.reshape(-1,8)\n",
        "    \n",
        "    return calculated\n",
        "\n",
        "def get_enclosing_box(corners):\n",
        "\n",
        "    x_ = corners[:,[0,2,4,6]]\n",
        "    y_ = corners[:,[1,3,5,7]]\n",
        "    \n",
        "    xmin = np.min(x_,1).reshape(-1,1)\n",
        "    ymin = np.min(y_,1).reshape(-1,1)\n",
        "    xmax = np.max(x_,1).reshape(-1,1)\n",
        "    ymax = np.max(y_,1).reshape(-1,1)\n",
        "        \n",
        "    final = np.hstack((xmin, ymin, xmax, ymax,corners[:,8:]))\n",
        "        \n",
        "    return final\n",
        "\n",
        "def bbox_area(bbox):\n",
        "    return (bbox[:,2] - bbox[:,0])*(bbox[:,3] - bbox[:,1])\n",
        "\n",
        "def clip_box(bbox, clip_box, alpha):\n",
        "\n",
        "    ar_ = (bbox_area(bbox))\n",
        "    x_min = np.maximum(bbox[:,0], clip_box[0]).reshape(-1,1)\n",
        "    y_min = np.maximum(bbox[:,1], clip_box[1]).reshape(-1,1)\n",
        "    x_max = np.minimum(bbox[:,2], clip_box[2]).reshape(-1,1)\n",
        "    y_max = np.minimum(bbox[:,3], clip_box[3]).reshape(-1,1)\n",
        "    \n",
        "    bbox = np.hstack((x_min, y_min, x_max, y_max, bbox[:,4:]))\n",
        "    \n",
        "    delta_area = ((ar_ - bbox_area(bbox))/ar_)\n",
        "    \n",
        "    mask = (delta_area < (1 - alpha)).astype(int)\n",
        "    \n",
        "    bbox = bbox[mask == 1,:]\n",
        "\n",
        "\n",
        "    return bbox"
      ],
      "id": "FAGwrchE0JvU",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "military-pricing"
      },
      "source": [
        "class Rescale(object):\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image, dog_score, coords = sample['image'], sample['dog_score'], sample['coords']\n",
        "        h, w = image.shape[:2]\n",
        "        if isinstance(self.output_size, int):\n",
        "            new_h, new_w = self.output_size * h / w, self.output_size * w / h\n",
        "        else:\n",
        "            new_h, new_w = self.output_size\n",
        "        new_h, new_w = int(new_h), int(new_w)\n",
        "        img = transform.resize(image, (new_h, new_w))\n",
        "        coords = coords * [new_w / w, new_h / h, new_w / w, new_h / h]\n",
        "        return {'image': img, 'dog_score': dog_score, 'coords': coords}\n",
        "\n",
        "class RandomHorizontalFlip(object):\n",
        "    def __init__(self, p=0.5):\n",
        "        self.p = p\n",
        "    def __call__(self, sample):\n",
        "        img, dog_score, bboxes = sample['image'], sample['dog_score'], sample['coords']\n",
        "        img_center = np.array(img.shape[:2])[::-1]/2\n",
        "        img_center = np.hstack((img_center, img_center))\n",
        "        if random.random() < self.p:\n",
        "            img =  img[:,::-1,:]\n",
        "            bboxes[:,[0,2]] += 2*(img_center[[0,2]] - bboxes[:,[0,2]])\n",
        "            box_w = abs(bboxes[:,0] - bboxes[:,2]) \n",
        "            bboxes[:,0] -= box_w\n",
        "            bboxes[:,2] += box_w\n",
        "        return {'image': img, 'dog_score': dog_score, 'coords': bboxes}\n",
        "\n",
        "class RandomRotation(object):\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        img, dog_score, bboxes = sample['image'], sample['dog_score'], sample['coords']\n",
        "        angle = random.randint(-45, 45)\n",
        "        w, h = img.shape[1], img.shape[0]\n",
        "        cx, cy = w//2, h//2\n",
        "        img = rotate_im(img, angle)\n",
        "        corners = get_corners(bboxes)\n",
        "        corners = np.hstack((corners, bboxes[:,4:]))\n",
        "        corners[:,:8] = rotate_bbox(corners[:,:8], angle, cx, cy, h, w)\n",
        "        new_bbox = get_enclosing_box(corners)\n",
        "        scale_factor_x = img.shape[1] / w\n",
        "        scale_factor_y = img.shape[0] / h\n",
        "        img = cv2.resize(img, (w,h))\n",
        "        new_bbox[:,:4] /= [scale_factor_x, scale_factor_y, scale_factor_x, scale_factor_y] \n",
        "        bboxes  = new_bbox\n",
        "        bboxes = clip_box(bboxes, [0,0,w, h], 0.25)\n",
        "\n",
        "        return {'image': img, 'dog_score': dog_score, 'coords': bboxes}\n",
        "\n",
        "class ToTensor(object):\n",
        "    def __call__(self, sample):\n",
        "        image, dog_score, coords = sample['image'], sample['dog_score'], sample['coords']\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        return {'image': torch.from_numpy(image).float(),\n",
        "                'dog_score': torch.from_numpy(dog_score).float(),\n",
        "                'coords': torch.from_numpy(coords).float()}"
      ],
      "id": "military-pricing",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxggNEqiF-cD"
      },
      "source": [
        "#4. Ребалансировка данных\n",
        "Датасет содержит 1037 изображений кошек и 2348 изображений собак => problem of class imbalance.\n",
        "Для решения этой проблемы нужно сделать upsample (oversample) картинок с кошками так, чтобы на выходе имелось одинаковое количкство данных обоих классов. Для того, чтобы сеть не переобучилась на одинаковых картинках кошек (одна и та же картинка может попасть в трейн и тест), а также для увеличения размера обучающей выборки, добавим аугментации."
      ],
      "id": "AxggNEqiF-cD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA_ksXK-gfqd"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/cats_dogs_dataset/annotations.csv')\n",
        "df_cats = df[df['class'] == 0]\n",
        "df_dogs = df[df['class'] == 1]\n",
        "#Upsample the small class to the size of the big class\n",
        "df_cats_upsampled = resample(df_cats, replace=True, \n",
        "                                n_samples = len(df_dogs), \n",
        "                                random_state=42)\n",
        "#Concatenate both datasets\n",
        "df_upsampled = pd.concat([df_dogs, df_cats_upsampled])\n",
        "#Save the dataset to the data folder\n",
        "df_upsampled.to_csv(r'/content/drive/MyDrive/cats_dogs_dataset/df_upsampled.csv',\n",
        "                    index=False)"
      ],
      "id": "WA_ksXK-gfqd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_im_BzJiSj"
      },
      "source": [
        "#5. Подготовка датасетов для обучения и тестирования сети"
      ],
      "id": "RX_im_BzJiSj"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "collectible-municipality"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/cats_dogs_dataset/df_upsampled.csv')\n",
        "#Split the data to train and test sets\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "#Get the train set with train transforms\n",
        "train_set = CatDogDataset(df=train,\n",
        "                            root_dir='/content/drive/MyDrive/cats_dogs_dataset',\n",
        "                            transform=transforms.Compose([\n",
        "                                               Rescale((240, 240)),\n",
        "                                               RandomHorizontalFlip(),\n",
        "                                               RandomRotation(),\n",
        "                                               ToTensor()]))\n",
        "#Get the test set with test transforms\n",
        "test_set = CatDogDataset(df=test,\n",
        "                            root_dir='/content/drive/MyDrive/cats_dogs_dataset',\n",
        "                            transform=transforms.Compose([\n",
        "                                               Rescale((240, 240)),\n",
        "                                               ToTensor()]))\n",
        "#Get the train and test loader\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=2)"
      ],
      "id": "collectible-municipality",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YqQGOFQJqgo"
      },
      "source": [
        "#6. Реализация архитектуры сети\n",
        "Я использовала transfer learning, модель -- Mobilenetv2, предобученная на ImageNet картинках, т. к. эта сеть достаточно простая в плане обучения, при этом дает неплохой результат + хорошо себя показала в Image Detection."
      ],
      "id": "_YqQGOFQJqgo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwV-r3yeUTx-",
        "outputId": "9f92880b-3ed6-42d6-c1f0-d1dce95cd9e2"
      },
      "source": [
        "#Define a net class\n",
        "class Mobilenetv2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Mobilenetv2, self).__init__()\n",
        "        #Choose MobileNetv2 pretrained on ImageNet\n",
        "        self.model = torch.hub.load('pytorch/vision', 'mobilenet_v2', pretrained=True)\n",
        "        #Rewrite the last (fully-connected) layers\n",
        "        self.model.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=self.model.classifier[1].in_features, out_features=128),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Dropout(0.3),\n",
        "            #We need 5 outputs\n",
        "            nn.Linear(64, 5),\n",
        "        )   \n",
        "        \n",
        "    def forward(self, x):\n",
        "        bs, _, _, _ = x.shape\n",
        "        x = self.model.features(x)\n",
        "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
        "        x = self.model.classifier(x)\n",
        "        #Нужна вероятность классов для бинарной классификации\n",
        "        dog_prob = torch.sigmoid(x[:, 0])\n",
        "        coords = x[:, 1:]\n",
        "        return {'dog_prob': dog_prob, 'coords': coords}\n",
        "\n",
        "net = Mobilenetv2()"
      ],
      "id": "dwV-r3yeUTx-",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_master\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mucGQDJnDyb",
        "outputId": "5bef2100-a006-4572-c14d-5f96ed687c48"
      },
      "source": [
        "#Model's architecture\n",
        "net"
      ],
      "id": "1mucGQDJnDyb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mobilenetv2(\n",
              "  (model): MobileNetV2(\n",
              "    (features): Sequential(\n",
              "      (0): ConvBNActivation(\n",
              "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU6(inplace=True)\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (3): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (4): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (5): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (6): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (7): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (8): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (9): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (10): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (11): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (12): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (13): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (14): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
              "            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (15): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (16): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (17): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): ConvBNActivation(\n",
              "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (1): ConvBNActivation(\n",
              "            (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
              "            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU6(inplace=True)\n",
              "          )\n",
              "          (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (18): ConvBNActivation(\n",
              "        (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU6(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (classifier): Sequential(\n",
              "      (0): Linear(in_features=1280, out_features=128, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.3, inplace=False)\n",
              "      (3): Linear(in_features=128, out_features=64, bias=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Dropout(p=0.3, inplace=False)\n",
              "      (6): Linear(in_features=64, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXs6_yZtKnVO"
      },
      "source": [
        "#7. Обучение и тестирование сети."
      ],
      "id": "SXs6_yZtKnVO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upper-train"
      },
      "source": [
        "#Use GPU if possible\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = net.to(device)\n",
        "#Criterion for classification\n",
        "criterion_binary = nn.BCELoss()\n",
        "#Criterion for regression\n",
        "criterion_multioutput = nn.MSELoss()\n",
        "#Setting an optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# A path to save the model\n",
        "PATH = \"model.pt\""
      ],
      "id": "upper-train",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjrJRV20iqzA"
      },
      "source": [
        "#Функция для подсчета метрики IoU\n",
        "def bb_intersection_over_union(boxA, boxB):\n",
        "    boxA = boxA[0]\n",
        "    boxB = boxB[0]\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
        "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
        "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
        "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "    return iou"
      ],
      "id": "MjrJRV20iqzA",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgXAJVdd4Q_R",
        "outputId": "2f27849b-4183-429c-dd25-a9b209ffe9a4"
      },
      "source": [
        "stats = {'epoch': [], 'train_loss': [], 'val_loss': [], 'acc': [], 'iou': []}\n",
        "n_epochs = 10\n",
        "val_loss_min = np.Inf\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(n_epochs):\n",
        "    batch_train_loss = []\n",
        "    stats['epoch'].append(epoch)\n",
        "    model.train()\n",
        "    for i, sample in enumerate(train_loader):\n",
        "        images = sample['image'].to(device)\n",
        "        dog_prob = sample['dog_score'].to(device)\n",
        "        coords = sample['coords'].to(device)\n",
        "        images /= 255\n",
        "        coords /= images.shape[2]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "\n",
        "        dog_prob_hat = outputs['dog_prob']\n",
        "        coords_hat = outputs['coords']\n",
        "        loss1 = criterion_binary(dog_prob_hat, dog_prob.squeeze().type(torch.float))\n",
        "        loss2 = criterion_multioutput(coords_hat, coords.squeeze().type(torch.float))\n",
        "        loss=loss1+loss2\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        batch_train_loss.append(loss.item())\n",
        "\n",
        "        if (i+1) % 10 == 0:\n",
        "            print (\"Epoch {}, Step [{}/{}] Loss: {:.4f}\"\n",
        "                   .format(epoch, i+1, total_step, loss.item()))\n",
        "    stats['train_loss'].append(batch_train_loss)\n",
        "\n",
        "# Test the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      batch_val_loss = []\n",
        "      batch_acc = []\n",
        "      batch_iou = []\n",
        "      for i, sample in enumerate(test_loader):\n",
        "        images = sample['image'].to(device)\n",
        "        dog_prob = sample['dog_score'].to(device)\n",
        "        coords = sample['coords'].to(device)\n",
        "        images /= 255\n",
        "        coords /= images.shape[2]\n",
        "        outputs = model(images)\n",
        "        dog_prob_hat = outputs['dog_prob']\n",
        "        coords_hat = outputs['coords']\n",
        "        val_loss1 = criterion_binary(dog_prob_hat, dog_prob.squeeze().type(torch.float))\n",
        "        val_loss2 = criterion_multioutput(coords_hat, coords.squeeze().type(torch.float))\n",
        "        val_loss=val_loss1+val_loss2\n",
        "        total += dog_prob.size(0)\n",
        "        correct += (torch.round(dog_prob_hat) == dog_prob.squeeze()).sum().item()\n",
        "        iou = bb_intersection_over_union(coords_hat, coords.squeeze())\n",
        "        batch_acc.append(100 * correct / total)\n",
        "        batch_iou.append(iou)\n",
        "        if (i+1) % 10 == 0:\n",
        "            print (\"Epoch {}, Loss: {:.4f}\"\n",
        "                   .format(epoch, val_loss.item()))\n",
        "        batch_val_loss.append(val_loss.item())\n",
        "      stats['acc'].append(batch_acc)\n",
        "      stats['iou'].append(batch_iou)\n",
        "      stats['val_loss'].append(batch_val_loss)\n",
        "      print('Mean accuracy of epoch on the test images: {} %'.\\\n",
        "            format(sum(stats['acc'][epoch])/len(stats['acc'][epoch])))\n",
        "      print('Mean IoU of epoch on the test images: {} '.\\\n",
        "            format(sum(stats['iou'][epoch])/len(stats['iou'][epoch])))\n",
        "      \n",
        "      # Saving the model if validation loss decreased to avoid overfitting\n",
        "      if val_loss < val_loss_min:\n",
        "          torch.save(net.state_dict(), PATH)\n",
        "          val_loss_min = val_loss\n",
        "          print('Saving model...')"
      ],
      "id": "YgXAJVdd4Q_R",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Step [10/59] Loss: 0.4419\n",
            "Epoch 0, Step [20/59] Loss: 0.4512\n",
            "Epoch 0, Step [30/59] Loss: 0.3302\n",
            "Epoch 0, Step [40/59] Loss: 0.2454\n",
            "Epoch 0, Step [50/59] Loss: 0.3774\n",
            "Epoch 0, Loss: 0.1044\n",
            "Mean accuracy of epoch on the test images: 95.11320165625352 %\n",
            "Mean IoU of epoch on the test images: 0.7191346883773804 \n",
            "Saving model...\n",
            "Epoch 1, Step [10/59] Loss: 0.2092\n",
            "Epoch 1, Step [20/59] Loss: 0.1961\n",
            "Epoch 1, Step [30/59] Loss: 0.2412\n",
            "Epoch 1, Step [40/59] Loss: 0.2103\n",
            "Epoch 1, Step [50/59] Loss: 0.1593\n",
            "Epoch 1, Loss: 0.1219\n",
            "Mean accuracy of epoch on the test images: 96.00341635930067 %\n",
            "Mean IoU of epoch on the test images: 0.7010229825973511 \n",
            "Epoch 2, Step [10/59] Loss: 0.2276\n",
            "Epoch 2, Step [20/59] Loss: 0.1114\n",
            "Epoch 2, Step [30/59] Loss: 0.1460\n",
            "Epoch 2, Step [40/59] Loss: 0.1107\n",
            "Epoch 2, Step [50/59] Loss: 0.0672\n",
            "Epoch 2, Loss: 0.1297\n",
            "Mean accuracy of epoch on the test images: 95.03343151381715 %\n",
            "Mean IoU of epoch on the test images: 0.7096962332725525 \n",
            "Saving model...\n",
            "Epoch 3, Step [10/59] Loss: 0.2607\n",
            "Epoch 3, Step [20/59] Loss: 0.1184\n",
            "Epoch 3, Step [30/59] Loss: 0.1550\n",
            "Epoch 3, Step [40/59] Loss: 0.0828\n",
            "Epoch 3, Step [50/59] Loss: 0.0631\n",
            "Epoch 3, Loss: 0.0887\n",
            "Mean accuracy of epoch on the test images: 96.42446201970803 %\n",
            "Mean IoU of epoch on the test images: 0.7222365140914917 \n",
            "Epoch 4, Step [10/59] Loss: 0.1669\n",
            "Epoch 4, Step [20/59] Loss: 0.1359\n",
            "Epoch 4, Step [30/59] Loss: 0.1010\n",
            "Epoch 4, Step [40/59] Loss: 0.1657\n",
            "Epoch 4, Step [50/59] Loss: 0.0691\n",
            "Epoch 4, Loss: 0.1117\n",
            "Mean accuracy of epoch on the test images: 99.10692901218167 %\n",
            "Mean IoU of epoch on the test images: 0.7366049885749817 \n",
            "Saving model...\n",
            "Epoch 5, Step [10/59] Loss: 0.0962\n",
            "Epoch 5, Step [20/59] Loss: 0.2596\n",
            "Epoch 5, Step [30/59] Loss: 0.1166\n",
            "Epoch 5, Step [40/59] Loss: 0.0613\n",
            "Epoch 5, Step [50/59] Loss: 0.1233\n",
            "Epoch 5, Loss: 0.1337\n",
            "Mean accuracy of epoch on the test images: 96.01005469855204 %\n",
            "Mean IoU of epoch on the test images: 0.70331871509552 \n",
            "Epoch 6, Step [10/59] Loss: 0.0561\n",
            "Epoch 6, Step [20/59] Loss: 0.0786\n",
            "Epoch 6, Step [30/59] Loss: 0.1341\n",
            "Epoch 6, Step [40/59] Loss: 0.0611\n",
            "Epoch 6, Step [50/59] Loss: 0.1151\n",
            "Epoch 6, Loss: 0.1077\n",
            "Mean accuracy of epoch on the test images: 97.69979016255613 %\n",
            "Mean IoU of epoch on the test images: 0.7167051434516907 \n",
            "Epoch 7, Step [10/59] Loss: 0.2313\n",
            "Epoch 7, Step [20/59] Loss: 0.0970\n",
            "Epoch 7, Step [30/59] Loss: 0.0454\n",
            "Epoch 7, Step [40/59] Loss: 0.1739\n",
            "Epoch 7, Step [50/59] Loss: 0.1171\n",
            "Epoch 7, Loss: 0.2483\n",
            "Mean accuracy of epoch on the test images: 96.85322290126146 %\n",
            "Mean IoU of epoch on the test images: 0.7221188545227051 \n",
            "Epoch 8, Step [10/59] Loss: 0.0455\n",
            "Epoch 8, Step [20/59] Loss: 0.0512\n",
            "Epoch 8, Step [30/59] Loss: 0.0534\n",
            "Epoch 8, Step [40/59] Loss: 0.1095\n",
            "Epoch 8, Step [50/59] Loss: 0.0346\n",
            "Epoch 8, Loss: 0.0653\n",
            "Mean accuracy of epoch on the test images: 97.41516312809532 %\n",
            "Mean IoU of epoch on the test images: 0.7236735224723816 \n",
            "Saving model...\n",
            "Epoch 9, Step [10/59] Loss: 0.1027\n",
            "Epoch 9, Step [20/59] Loss: 0.0718\n",
            "Epoch 9, Step [30/59] Loss: 0.0565\n",
            "Epoch 9, Step [40/59] Loss: 0.0599\n",
            "Epoch 9, Step [50/59] Loss: 0.0569\n",
            "Epoch 9, Loss: 0.1120\n",
            "Mean accuracy of epoch on the test images: 94.21834294424055 %\n",
            "Mean IoU of epoch on the test images: 0.7491838932037354 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhpJdY9-O6YH"
      },
      "source": [
        "#8. Инференс и оценка времени предсказания"
      ],
      "id": "VhpJdY9-O6YH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3icVrf17cdJ",
        "outputId": "8ef62652-dfd1-4b29-bfb7-7da1e4862f57"
      },
      "source": [
        "import time\n",
        "# Loading the model for inference\n",
        "model = net.to(device)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "start_time = time.time()\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for i, sample in enumerate(test_loader):\n",
        "    images = sample['image'].to(device)\n",
        "    images /= 255\n",
        "    outputs = model(images)\n",
        "    dog_prob_hat = outputs['dog_prob']\n",
        "    coords_hat = outputs['coords']\n",
        "inference_time = time.time() - start_time\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "id": "T3icVrf17cdJ",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- 29.862287282943726 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAACvcQevx7t",
        "outputId": "b128cf00-1e2c-4d09-af9e-9a78cc784996"
      },
      "source": [
        "sum_iou = sum(stats['iou'][8])\n",
        "print('mIoU: {}%, Accuracy: {}%, {} seconds, {} train, {} test'.format( \n",
        "    round(sum_iou.item()/len(stats['iou'][8]) * 100, 2), \n",
        "    round(sum(stats['acc'][8])/len(stats['acc'][8]), 2), \n",
        "    round(inference_time, 2),\n",
        "    len(train_set), \n",
        "    len(test_set)))"
      ],
      "id": "CAACvcQevx7t",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mIoU: 72.37%, Accuracy: 97.42%, 29.86 seconds, 3756 train, 940 test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0G02Zpgeamd"
      },
      "source": [
        ""
      ],
      "id": "V0G02Zpgeamd",
      "execution_count": null,
      "outputs": []
    }
  ]
}